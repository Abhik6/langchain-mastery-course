{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain Essentials Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain is one of the most popular open source libraries for AI Engineers. It's goal is to abstract away the complexity in building AI software, provide easy-to-use building blocks, and make it easier when switching between AI service providers.\n",
    "\n",
    "In this example, we will introduce LangChain's Agents, adding the ability to use tools such as search and calculators to complete tasks that normal LLMs cannot fufil. In this example we will be using Meta's `llama3.2:1b-instruct-fp16`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> ⚠️ We will be using Meta for this example allowing us to run everything via API. If you would like to use OpenAI instead, please see the [OpenAI version](https://github.com/aurelio-labs/langchain-course/blob/main/notebooks/openai/05-custom-agents-openai.ipynb) of this example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools are a way augment our LLMs with code execution. A tool is simply a function formatted so that our agent can undertstand how to use it, and then execute it. Let's start by creating a few simple tools.\n",
    "\n",
    "We can use the `@tool` decorator to create an LLM-compatible tool from a standard python function — this function should include a few things for optimal performance:\n",
    "\n",
    "* A docstring describing what the tool does and when it should be used, this will be read by our LLM/agent and used to decide when to use the tool, and also how to use the tool.\n",
    "\n",
    "* Clear parameter names that ideally tell the LLM what each parameter is, if it isn't clear we make sure the docstring explains what the parameter is for and how to use it.\n",
    "\n",
    "* Both parameter and return type annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# Define the multiply tool\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "# Define the exponentiate tool\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `@tool` decorator our function is turned into a `StructuredTool` object, which we can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x10b8820c0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the tool name, description, and arg schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `args_schema` is a pydantic model that is transformed into the JSON schema above and passed into our LLM, it is this that defines _how_ the tool is used for the LLM. We can see this with other tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Raise 'x' to the power of 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'exponentiate',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When invoking the tool, a JSON string output by the LLM will be parsed into JSON and then consumed as kwargs, similar to the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is then passed into the tool function as `kwargs` (keyword arguments) as indicated by the `**` operator - the `**` operator is used to unpack the dictionary into keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This covers the basics of tools and how they work, let's move on to creating the agent itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to construct a simple tool calling agent. We will use **L**ang**C**hain **E**pression **L**anguage (LCEL) to construct the agent. We will cover LCEL more in the next chapter, but for now - all we need to know is that our agent will be constructed using syntax and components like so:\n",
    "\n",
    "\n",
    "```\n",
    "agent = (\n",
    "    <input parameters, including chat history and user query>\n",
    "    | <prompt>\n",
    "    | <LLM with tools>\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need this agent to remember previous interactions within the conversation. To do that, we will use the `ChatPromptTemplate` with a system message, a placeholder for our chat history, a placeholder for the user query, and finally a placeholder for the agent scratchpad.\n",
    "\n",
    "The agent scratchpad is where the agent will write it's _\"notes\"_ as it is working through multiple internal thought and tool-use steps to produce a final output to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"Scratchpad: {agent_scratchpad}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by initializing the 1B parameter Llama 3.2 model, fine-tuned for instruction following. We pull the model from Ollama by switching to our terminal and executing:\n",
    "\n",
    "ollama pull llama3.2:1b-instruct-fp16\n",
    "\n",
    "Once the model has finished downloading, we initialize it in LangChain using the ChatOllama class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"llama3.2:1b-instruct-fp16\"\n",
    "\n",
    "# initialize one LLM with temperature 0.0, this makes the LLM more deterministic\n",
    "llm = ChatOllama(temperature=0.0, model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add tools to our LLM, we will use the `bind_tools` method within the LCEL constructor, which will take our tools and add them to the LLM. We'll also include the `tool_choice=\"any\"` argument to `bind_tools`, which tells the LLM that it _MUST_ use a tool, ie it cannot provide a final answer directly (in therefore not using a tool):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", \"\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We invoke the agent with the `invoke` method, passing in the input and chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bI8aZpMN1y907LncsX9rhY6y', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 205, 'total_tokens': 223, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_01aeff40ea', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-043d12fc-b806-419e-b940-3aec5b727450-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_bI8aZpMN1y907LncsX9rhY6y', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 18, 'total_tokens': 223, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we set `tool_choice=\"any\"` to force the tool output, the usual `content` field will be empty as that field is used for natural language output, ie the _final answer_ of the LLM. To find our tool output, we need to look at the `tool_calls` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'call_bI8aZpMN1y907LncsX9rhY6y',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we have the tool `name` that our LLM wants to use, and the `args` that it wants to pass to that tool. We can see that the tool `add` is being used with the arguments `x=10` and `y=10`. The tool itself has _not_ been executed, we need to write that part of the agent code ourselves.\n",
    "\n",
    "Executing the tool code requires two steps:\n",
    "\n",
    "1. Map the tool `name` to the tool function.\n",
    "2. Execute the tool function with the generated `args`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tool name to function mapping\n",
    "name2tool = {tool.name: tool.func for tool in tools}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now execute to get our answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output = name2tool[out.tool_calls[0][\"name\"]](**out.tool_calls[0][\"args\"])\n",
    "tool_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is our answer and tool execution logic. We feed this back into our LLM via the `agent_scratchpad` placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_vIKn0eWVupXsSpJBT1budTHr', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 210, 'total_tokens': 228, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_01aeff40ea', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-701a37d5-6625-4e23-adfe-e1897e33b603-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_vIKn0eWVupXsSpJBT1budTHr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 210, 'output_tokens': 18, 'total_tokens': 228, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": (\n",
    "        f\"The {out.tool_calls[0]['name']} tool returned {tool_output}\"\n",
    "    )\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite having the answer in our `agent_scratchpad`, the LLM still tries to use the tool _again_. This is because when binding the tools to the LLM, we set `tool_choice=\"any\"`, which tells the LLM that it _MUST_ use a tool, ie it cannot provide a final answer.\n",
    "\n",
    "There's two options to fix this:\n",
    "\n",
    "1. Set `tool_choice=\"auto\"` to tell the LLM that it can choose to use a tool or provide a final answer.\n",
    "\n",
    "2. Create a `final_answer` tool - we'll explain this in a moment.\n",
    "\n",
    "First, let's try option **1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", \"\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"auto\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start from the start again, so `agent_scratchpad` is empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YOCTOCe2iHyIJhcfaiDVafpA', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 205, 'total_tokens': 223, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_01aeff40ea', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3dc7fb9a-067c-43b8-8b7a-89e4b0730672-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_YOCTOCe2iHyIJhcfaiDVafpA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 18, 'total_tokens': 223, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we execute the tool and pass it's output into the `agent_scratchpad` placeholder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10 + 10 equals 20.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 210, 'total_tokens': 220, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_01aeff40ea', 'finish_reason': 'stop', 'logprobs': None}, id='run-3bfbae86-b4e5-4e9e-a9ec-1640acbadf53-0', usage_metadata={'input_tokens': 210, 'output_tokens': 10, 'total_tokens': 220, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output = name2tool[out.tool_calls[0][\"name\"]](**out.tool_calls[0][\"args\"])\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": (\n",
    "        f\"The {out.tool_calls[0]['name']} tool returned {tool_output}\"\n",
    "    )\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the final answer in the `content` field! This method is perfectly functional however we recommend option **2** as it provides more control over the agent's output.\n",
    "\n",
    "There are several reasons that option **2** can provide more control, those are:\n",
    "\n",
    "* Removes the possibility of an agent using the irect `content` field when not appropriate, for example some LLMs (paritucularly smaller LLMs) may try and use the `content` field when trying to a tool.\n",
    "\n",
    "* We can enforce a specific structured output in our answers, this can be particularly useful when we have specific outputs that we require, for example a RAG agent may return a natural language answer, but also a list of sources that were used to generate that answer.\n",
    "\n",
    "* TK\n",
    "\n",
    "To implement option **2** we must create a `final_answer` tool. We will add a `tools_used` field to give a little bit of structure to our output - in an real-world use-case we probably wouldn't want to generate this field, but it's useful for our example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `final_answer` tool _doesn't_ necessarily need to do anything, in this example we're using purely to structure our final response. We can now add this tool to our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [final_answer, add, subtract, multiply, exponentiate]\n",
    "\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", \"\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we invoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'call_fhhm33BCyJdxlyguAuP9STEK',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We execute the tool and provide it's output to the agent again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_reBCXwxUOIePCItSSEuTKGCn', 'function': {'arguments': '{\"answer\":\"10 + 10 equals 20.\",\"tools_used\":[\"functions.add\"]}', 'name': 'final_answer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 282, 'total_tokens': 310, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aff59efd-9186-4ea5-81a9-32c9c17a5cc2-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']}, 'id': 'call_reBCXwxUOIePCItSSEuTKGCn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 282, 'output_tokens': 28, 'total_tokens': 310, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_out = name2tool[out.tool_calls[0][\"name\"]](**out.tool_calls[0][\"args\"])\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": (\n",
    "        f\"The {out.tool_calls[0]['name']} tool returned {tool_out}\"\n",
    "    )\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `content` is still empty, this is because we are forcing tool use. But, we now have the `final_answer` tool, which is being used via the `tool_calls` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'final_answer',\n",
       "  'args': {'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']},\n",
       "  'id': 'call_reBCXwxUOIePCItSSEuTKGCn',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are seeing the `final_answer` tool here, we don't pass this back into our agent and instead this tell us to stop execution and pass the `args` output onto our downstream process or user directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Custom Agent Execution Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've worked through each step of our agent code, but it doesn't run without us runnning every step. We need to write a class that will handle all of the logic that we just worked through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, max_iterations: int = 3):\n",
    "        self.chat_history = []\n",
    "        self.max_iterations = max_iterations\n",
    "        self.agent: RunnableSerializable = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", \"\")\n",
    "            }\n",
    "            | prompt\n",
    "            | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    "        )\n",
    "\n",
    "    def invoke(self, input: str) -> dict:\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching a final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = \"\"\n",
    "        while count < self.max_iterations:\n",
    "            # invoke a step for the agent to generate a tool call\n",
    "            out = self.agent.invoke({\n",
    "                \"input\": input,\n",
    "                \"chat_history\": self.chat_history,\n",
    "                \"agent_scratchpad\": agent_scratchpad\n",
    "            })\n",
    "            # if the tool call is the final answer tool, we stop\n",
    "            if out.tool_calls[0][\"name\"] == \"final_answer\":\n",
    "                break\n",
    "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
    "            tool_out = name2tool[out.tool_calls[0][\"name\"]](**out.tool_calls[0][\"args\"])\n",
    "            # add the tool output to the agent scratchpad\n",
    "            action_str = f\"The {out.tool_calls[0]['name']} tool returned {tool_out}\"\n",
    "            agent_scratchpad += \"\\n\" + action_str\n",
    "            # add a print so we can see intermediate steps\n",
    "            print(f\"{count}: {action_str}\")\n",
    "            count += 1\n",
    "        # add the final output to the chat history\n",
    "        final_answer = out.tool_calls[0][\"args\"]\n",
    "        # this is a dictionary, so we convert it to a string for compatibility with\n",
    "        # the chat history\n",
    "        final_answer_str = json.dumps(final_answer)\n",
    "        self.chat_history.append({\"input\": input, \"output\": final_answer_str})\n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content=input),\n",
    "            AIMessage(content=final_answer_str)\n",
    "        ])\n",
    "        # return the final answer in dict form\n",
    "        return final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize the agent executor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CustomAgentExecutor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And test the `invoke` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: The add tool returned 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(input=\"What is 10 + 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that we've built our own _custom_ agent executor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can test the output's of our agent, firstly we tell it our name, then we will try and get it to call some tools we gave it earlier, then we will try and get the agent to recall our name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Josh! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My name is Josh',\n",
       " 'chat_history': [HumanMessage(content='My name is Josh', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Josh! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Nice to meet you, Josh! How can I assist you today?'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"My name is Josh\", \"chat_history\": memory})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'x': 9, 'y': 10}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m19.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 4, 'y': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m8.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'x': 2, 'y': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m8.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `subtract` with `{'x': 19, 'y': 8}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m-11.0\u001b[0m\u001b[32;1m\u001b[1;3mThe result of the expression \\(9 + 10 - 4 \\times 2^3\\) is \\(-11\\).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is nine plus 10, minus 4 * 2, to the power of 3',\n",
       " 'chat_history': [HumanMessage(content='My name is Josh', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Josh! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of the expression \\\\(9 + 10 - 4 \\\\times 2^3\\\\) is \\\\(-11\\\\).', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The result of the expression \\\\(9 + 10 - 4 \\\\times 2^3\\\\) is \\\\(-11\\\\).'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is nine plus 10, minus 4 * 2, to the power of 3\", \"chat_history\": memory})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Josh.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name',\n",
       " 'chat_history': [HumanMessage(content='My name is Josh', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Josh! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of the expression \\\\(9 + 10 - 4 \\\\times 2^3\\\\) is \\\\(-11\\\\).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Josh.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is Josh.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is my name\", \"chat_history\": memory})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SerpAPI Weather Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Serpapi from the load_tools function, this will allow us to search the current web. To do this too, you will need a SERPAPI_API_KEY, you can get a free plan which will grant you 100 searches per week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will pull a tool from the load_tools function LangChain offers, this will pull our SerpAPI which allows us to search the web for answers, however this does require an API key as mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = load_tools(\n",
    "   ['serpapi'],\n",
    "    llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These custom tools can look into your IP address, find out where you are currently, then we will also use a secondary function to get the current date and time, then we will use this information to feed into the SerpAPI to find us the weather pattern in your area and at the time of the function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "@tool\n",
    "def get_location_from_ip():\n",
    "    \"\"\"Get the geographical location based on the IP address.\"\"\"\n",
    "    try:\n",
    "        response = requests.get('https://ipinfo.io/json')\n",
    "        data = response.json()\n",
    "        if 'loc' in data:\n",
    "            latitude, longitude = data['loc'].split(',')\n",
    "            return f\"Latitude: {latitude}, Longitude: {longitude}, City: {data.get('city', 'N/A')}, Country: {data.get('country', 'N/A')}\"\n",
    "        else:\n",
    "            return \"Location could not be determined.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred: {e}\"\n",
    "    \n",
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"Return the current date and time.\"\"\"\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now because we don't want a memory variable involved with this AI we can get rid of the chat_history variable which was being used in the prompt previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all mainly the same as before, but without the memory and a new set of tools for us to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [toolbox[0], get_current_datetime, get_location_from_ip]\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For me I have to specify to the AI as I live in the UK and alot of places in the UK also exist in USA, which is why I explicitly state to use the country in the search as well as the town / city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_datetime` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m2024-11-15 10:26:53\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_location_from_ip` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLatitude: 53.1333, Longitude: -1.2000, City: Mansfield, Country: GB\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `Mansfield weather`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '48', 'unit': 'Fahrenheit', 'precipitation': '6%', 'humidity': '97%', 'wind': '7 mph', 'location': 'Mansfield, OH', 'date': 'Friday 5:00 AM', 'weather': 'Cloudy'}\u001b[0m\u001b[32;1m\u001b[1;3mThe current date and time is **November 15, 2024, 10:26 AM**. \n",
      "\n",
      "You are located in **Mansfield, UK**. The weather there is **cloudy**, with a temperature of **48°F**, humidity at **97%**, and wind speed of **7 mph**. There is a **6% chance of precipitation**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'firstly what is the date and time right now, then what is the weather like is where I am in right now but becareful as there can be more then two places on earth with the same name?',\n",
       " 'output': 'The current date and time is **November 15, 2024, 10:26 AM**. \\n\\nYou are located in **Mansfield, UK**. The weather there is **cloudy**, with a temperature of **48°F**, humidity at **97%**, and wind speed of **7 mph**. There is a **6% chance of precipitation**.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"firstly what is the date and time right now, then what is the weather like is where I am in right now but becareful as there can be more then two places on earth with the same name?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
