{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be modifying ReAct a little to take advantage of the progress that has been made in LLMs since the paper was originally released. We make two modifications:\n",
    "\n",
    "1. We use chat models, when ReAct was released LLMs were not fine-tuned specifically for chat and instead were prompted to generate chat-like dialogues. Most SotA LLMs nowadays are built specifically for chat and so the input into them must be modified to be chat-model friendly.\n",
    "\n",
    "2. We will use JSON-mode to force structured output from our LLMs. The original ReAct method simply instructed the LLM to output everything in a particular format. That works but is prone to occasionally breaking. By forcing JSON-like output we reduce the likelihood of poorly structured output. To accomodate this we modify the instructions to ask for `thought` and `action` steps in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant. Given a user query you must provide a `thought` and\n",
    "`action` step that take one step towards solving the user's query. Both the\n",
    "`thought` and `action` steps will be contained in JSON output.\n",
    "\n",
    "The `thought` is a JSON object with a `thoughts` key containing your thoughts\n",
    "on how to solve the user's query.\n",
    "\n",
    "The `action` step is a JSON object with a `tool` key containing the name of the\n",
    "tool to use and a `args` key containing a JSON object of arguments to pass to\n",
    "the tool.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "user: What is the weather in Tokyo?\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"thought\": {\"thoughts\": \"I need to find out the current temperature in Tokyo\"},\n",
    "  \"action\": {\"tool\": \"search\", \"args\": {\"query\": \"current temperature in Tokyo\"}}\n",
    "}\n",
    "```\n",
    "\n",
    "If you have performed any previous thought and action steps, you will find them\n",
    "below under the \"Previous Steps\" section. Alongside these you will find an\n",
    "`observation` key containing the output of those previous actions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't defined any tools or agent logic yet, but let's see what type of output\n",
    "our LLM produces if we prompt it with this system prompt.\n",
    "\n",
    "Make sure you have Llama 3.2 downloaded already via:\n",
    "\n",
    "```\n",
    "ollama run llama3.2:3b-instruct-fp16\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"thought\": {\n",
      "    \"thoughts\": \"I need to find out the current date\"\n",
      "  },\n",
      "  \"action\": {\n",
      "    \"tool\": \"date\",\n",
      "    \"args\": {}\n",
      "  }\n",
      "}\n",
      "  \n",
      "  \n",
      "  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "res = ollama.chat(\n",
    "    model=\"llama3.2:3b-instruct-fp16\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"What is the date today?\"},\n",
    "    ],\n",
    "    format=\"json\",\n",
    ")\n",
    "\n",
    "print(res[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we're outputting the correct format *however* we don't have a `date` tool, in fact, we don't have *any* tools! Let's define some.\n",
    "\n",
    "First, we'll define a search tool. This tool will allow our agent to search the web for information. To implement it we will use the Tavily API, it comes with a number of requests for free but we do need to [sign up for the API](https://app.tavily.com/home) and get an API key to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the weather in Tokyo?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'Tokyo, Japan 14 day weather forecast - timeanddate.com',\n",
       "   'url': 'https://www.timeanddate.com/weather/japan/tokyo/ext',\n",
       "   'content': 'Tokyo 14 Day Extended Forecast. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 68 °F. Partly sunny. (Weather station: Tokyo Heliport, Japan). See more current weather.',\n",
       "   'score': 0.9930153,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Hourly forecast for Tokyo, Japan - timeanddate.com',\n",
       "   'url': 'https://www.timeanddate.com/weather/japan/tokyo/hourly',\n",
       "   'content': 'Hour-by-Hour Forecast for Tokyo, Japan. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 70 °F. Partly sunny. (Weather station: Tokyo Heliport, Japan). See more current weather.',\n",
       "   'score': 0.9920312,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Weather for Tokyo, Japan - timeanddate.com',\n",
       "   'url': 'https://www.timeanddate.com/weather/japan/tokyo',\n",
       "   'content': 'Current weather in Tokyo and forecast for today, tomorrow, and next 14 days',\n",
       "   'score': 0.93913656,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Tokyo, Tokyo, Japan Weather Forecast | AccuWeather',\n",
       "   'url': 'https://www.accuweather.com/en/jp/tokyo/226396/weather-forecast/226396',\n",
       "   'content': 'Get the latest weather forecast for Tokyo, Japan, with hourly, daily, and 15-day details. Check the temperature, humidity, wind, rain, and snow from AccuWeather.',\n",
       "   'score': 0.9119669,\n",
       "   'raw_content': None},\n",
       "  {'title': 'Tokyo, Tokyo, Japan Current Weather | AccuWeather',\n",
       "   'url': 'https://www.accuweather.com/en/jp/tokyo/226396/current-weather/226396',\n",
       "   'content': 'Current weather in Tokyo, Tokyo, Japan. Check current conditions in Tokyo, Tokyo, Japan with radar, hourly, and more.',\n",
       "   'score': 0.9014011,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 3.05}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "TAVILY_API_KEY = \"tvly-...\"\n",
    "\n",
    "tavily_url = \"https://api.tavily.com\"\n",
    "\n",
    "res = requests.post(\n",
    "    f\"{tavily_url}/search\",\n",
    "    json={\n",
    "        \"api_key\": TAVILY_API_KEY,\n",
    "        \"query\": \"What is the weather in Tokyo?\"\n",
    "    },\n",
    ")\n",
    "\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we don't return much useful info here beyond that we have some URLs that *do contain* the information we need. Fortunately, we can extract this information via Tavily's `/extract` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [x[\"url\"] for x in res.json()[\"results\"]]\n",
    "\n",
    "res = requests.post(\n",
    "    f\"{tavily_url}/extract\",\n",
    "    json={\n",
    "        \"api_key\": TAVILY_API_KEY,\n",
    "        \"urls\": urls\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'url': 'https://www.timeanddate.com/weather/japan/tokyo',\n",
       "   'raw_content': \"Weather in Tokyo, Japan\\nCool.\\nFeels Like: 58\\xa0°FForecast: 74 / 52\\xa0°FWind: 2 mph ↑ from South\\nUpcoming 5 hours\\nSee more hour-by-hour weather\\nForecast for the next 48 hours\\n14 day forecast, day-by-dayHour-by-hour forecast for next week\\nYesterday's weather\\nCool. 72 / 58\\xa0°FHumidity: 67%. Wind: 5 mph ↑ from North\\nMore weather last week\\nCurrently at nearby stations\\nTokyo International Airport: (11\\xa0mi)\\nPassing clouds.\\nYokota Ab: (20\\xa0mi)\\nClear. (1 hour ago)\\nNational Airport: (39\\xa0mi)\\nPassing clouds.\\nMore weather in Japan\\nForecast for the next 2 weeks\\nView historic weather\\n74 / 52\\xa0°F\\n73 / 56\\xa0°F\\n58 / 54\\xa0°F\\n62 / 50\\xa0°F\\n62 / 48\\xa0°F\\n62 / 49\\xa0°F\\n63 / 52\\xa0°F\\n65 / 54\\xa0°F\\n69 / 59\\xa0°F\\n72 / 60\\xa0°F\\n72 / 60\\xa0°F\\n71 / 59\\xa0°F\\n69 / 59\\xa0°F\\n65 / 57\\xa0°F\\n64 / 56\\xa0°F\\nDetailed forecast for 14 days\\n Need some help?\\n© Time and Date AS 1995–2024\\n\\n © Time and Date AS 1995–2024. \\n Privacy & Terms\\n\\n\"}],\n",
       " 'failed_results': [{'url': 'https://www.timeanddate.com/weather/japan/tokyo/hourly',\n",
       "   'error': 'Failed to get content'},\n",
       "  {'url': 'https://www.timeanddate.com/weather/japan/tokyo/ext',\n",
       "   'error': 'Failed to get content'},\n",
       "  {'url': 'https://www.accuweather.com/en/jp/tokyo/226396/weather-forecast/226396',\n",
       "   'error': 'Request timed out'},\n",
       "  {'url': 'https://www.accuweather.com/en/jp/tokyo/226396/current-weather/226396',\n",
       "   'error': 'Request timed out'}],\n",
       " 'response_time': 6.29}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most requests didn't work, but that's okay we made multiple requests and fortunately received one result that looks perfect, we can extract that information like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather in Tokyo, Japan\n",
      "Cool.\n",
      "Feels Like: 58 °FForecast: 74 / 52 °FWind: 2 mph ↑ from South\n",
      "Upcoming 5 hours\n",
      "See more hour-by-hour weather\n",
      "Forecast for the next 48 hours\n",
      "14 day forecast, day-by-dayHour-by-hour forecast for next week\n",
      "Yesterday's weather\n",
      "Cool. 72 / 58 °FHumidity: 67%. Wind: 5 mph ↑ from North\n",
      "More weather last week\n",
      "Currently at nearby stations\n",
      "Tokyo International Airport: (11 mi)\n",
      "Passing clouds.\n",
      "Yokota Ab: (20 mi)\n",
      "Clear. (1 hour ago)\n",
      "National Airport: (39 mi)\n",
      "Passing clouds.\n",
      "More weather in Japan\n",
      "Forecast for the next 2 weeks\n",
      "View historic weather\n",
      "74 / 52 °F\n",
      "73 / 56 °F\n",
      "58 / 54 °F\n",
      "62 / 50 °F\n",
      "62 / 48 °F\n",
      "62 / 49 °F\n",
      "63 / 52 °F\n",
      "65 / 54 °F\n",
      "69 / 59 °F\n",
      "72 / 60 °F\n",
      "72 / 60 °F\n",
      "71 / 59 °F\n",
      "69 / 59 °F\n",
      "65 / 57 °F\n",
      "64 / 56 °F\n",
      "Detailed forecast for 14 days\n",
      " Need some help?\n",
      "© Time and Date AS 1995–2024\n",
      "\n",
      " © Time and Date AS 1995–2024. \n",
      " Privacy & Terms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res.json()[\"results\"][0][\"raw_content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so this is how we use the Tavily API to search the web, now let's implement this logic within a function which we can then use as a tool (ie action) for our ReAct agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str):\n",
    "    \"\"\"Use this tool to search the web for information.\"\"\"\n",
    "    # first we need to search the web for the query\n",
    "    res = requests.post(\n",
    "        f\"{tavily_url}/search\",\n",
    "        json={\n",
    "            \"api_key\": TAVILY_API_KEY,\n",
    "            \"query\": query\n",
    "        },\n",
    "    )\n",
    "    # now get all the URLs from the search results\n",
    "    urls = [x[\"url\"] for x in res.json()[\"results\"]]\n",
    "    # now extract the information from the URLs\n",
    "    res = requests.post(\n",
    "        f\"{tavily_url}/extract\",\n",
    "        json={\n",
    "            \"api_key\": TAVILY_API_KEY,\n",
    "            \"urls\": urls\n",
    "        },\n",
    "    )\n",
    "    # we return just the top result as otherwise we overload our LLM\n",
    "    return res.json()[\"results\"][0][\"raw_content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yahoo Weather\n",
      "My Locations\n",
      "Around the World\n",
      "Tokyo\n",
      "Japan\n",
      "Mostly Sunny\n",
      "Forecast\n",
      "5 PM\n",
      "6 PM\n",
      "7 PM\n",
      "8 PM\n",
      "9 PM\n",
      "10 PM\n",
      "11 PM\n",
      "12 AM\n",
      "1 AM\n",
      "2 AM\n",
      "3 AM\n",
      "4 AM\n",
      "5 AM\n",
      "6 AM\n",
      "7 AM\n",
      "8 AM\n",
      "9 AM\n",
      "10 AM\n",
      "11 AM\n",
      "12 PM\n",
      "1 PM\n",
      "2 PM\n",
      "3 PM\n",
      "4 PM\n",
      "Clear with a high of 42 °F (5.6 °C) and a 49% chance of precipitation. Winds NW at 24 mph (38.6 kph).\n",
      "Night - Clear with a 28% chance of precipitation. Winds variable at 7 to 25 mph (11.3 to 40.2 kph). The overnight low will be 34 °F (1.1 °C).\n",
      "Sunny today with a high of 54 °F (12.2 °C) and a low of 32 °F (0 °C).\n",
      "Mostly cloudy today with a high of 56 °F (13.3 °C) and a low of 40 °F (4.4 °C).\n",
      "Rain today with a high of 52 °F (11.1 °C) and a low of 40 °F (4.4 °C). There is a 66% chance of precipitation.\n",
      "Rain today with a high of 47 °F (8.3 °C) and a low of 41 °F (5 °C). There is a 77% chance of precipitation.\n",
      "Showers today with a high of 48 °F (8.9 °C) and a low of 42 °F (5.6 °C). There is a 75% chance of precipitation.\n",
      "Mostly cloudy today with a high of 54 °F (12.2 °C) and a low of 39 °F (3.9 °C). There is a 51% chance of precipitation.\n",
      "Showers today with a high of 48 °F (8.9 °C) and a low of 34 °F (1.1 °C). There is a 51% chance of precipitation.\n",
      "Mostly sunny today with a high of 44 °F (6.7 °C) and a low of 32 °F (0 °C).\n",
      "Sunny today with a high of 51 °F (10.6 °C) and a low of 35 °F (1.7 °C).\n",
      "Sunny today with a high of 52 °F (11.1 °C) and a low of 37 °F (2.8 °C).\n",
      "Precipitation\n",
      "Wind & Pressure\n",
      "Details\n",
      "Today - Clear with a high of 42 °F (5.6 °C) and a 49% chance of precipitation. Winds NW at 24 mph (38.6 kph).\n",
      "Tonight - Clear with a 28% chance of precipitation. Winds variable at 7 to 25 mph (11.3 to 40.2 kph). The overnight low will be 34 °F (1.1 °C).\n",
      "Sun & Moon\n",
      "Map\n"
     ]
    }
   ],
   "source": [
    "print(search(query=\"What is the weather in Tokyo?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's define two more tools...\n",
    "\n",
    "We will create a simple \"current date and time tool\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def date():\n",
    "    \"\"\"Use this tool to get the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And very importantly, we will define a tool that will be triggered when our LLM would like to provide it's final answer to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(text: str):\n",
    "    \"\"\"Use this tool to provide your final answer to the user.\"\"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate an additional part to our `system_prompt` to explain which tools are available to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search',\n",
       "  'description': 'Use this tool to search the web for information.',\n",
       "  'args': {'query': 'str'}},\n",
       " {'name': 'date',\n",
       "  'description': 'Use this tool to get the current date and time.',\n",
       "  'args': {}},\n",
       " {'name': 'answer',\n",
       "  'description': 'Use this tool to provide your final answer to the user.',\n",
       "  'args': {'text': 'str'}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "# we get the various parameters/description from each tool function\n",
    "tools = [search, date, answer]\n",
    "tool_descriptions = [\n",
    "    {\n",
    "        \"name\": tool.__name__,\n",
    "        \"description\": str(inspect.getdoc(tool)),\n",
    "        \"args\": {\n",
    "            k: str(v).split(\": \")[1] for k, v in inspect.signature(tool).parameters.items()\n",
    "        }\n",
    "    }\n",
    "    for tool in tools\n",
    "]\n",
    "tool_descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's parse these into text instructions that can be added to our `system_prompt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have access to the following tools ONLY, no other tools exist:\n",
      "\n",
      "{'name': 'search', 'description': 'Use this tool to search the web for information.', 'args': {'query': 'str'}}\n",
      "{'name': 'date', 'description': 'Use this tool to get the current date and time.', 'args': {}}\n",
      "{'name': 'answer', 'description': 'Use this tool to provide your final answer to the user.', 'args': {'text': 'str'}}\n"
     ]
    }
   ],
   "source": [
    "tool_instructions = (\n",
    "    \"You have access to the following tools ONLY, no other tools exist:\\n\\n\"\n",
    "    + \"\\n\".join([str(x) for x in tool_descriptions])\n",
    ")\n",
    "print(tool_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try calling our LLM again with these additional instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"thought\": {\n",
      "    \"thoughts\": \"I need to find out what Ollama refers to in the context of AI\"\n",
      "  },\n",
      "  \"action\": {\n",
      "    \"tool\": \"search\",\n",
      "    \"args\": {\"query\": \"Ollama AI\"}\n",
      "  }\n",
      "}\n",
      "\n",
      "  \n",
      "  \n",
      "\n",
      "  \n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = ollama.chat(\n",
    "    model=\"llama3.2:3b-instruct-fp16\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt}\\n\\n{tool_instructions}\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is Ollama in the context of AI?\"},\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    ")\n",
    "\n",
    "step = res[\"message\"][\"content\"]\n",
    "print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Our LLM has correctly generated the query we need. We can now parse this and pass it into the `search` tool as specified by our LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama Explained: Transforming AI Accessibility and Language Processing\n",
      "In the rapidly evolving landscape of artificial intelligence (AI), accessibility and innovation are paramount. Among the myriad platforms and tools emerging in this space, one name stands out: Ollama. But what exactly is Ollama, and why is it garnering attention in the AI community? This article delves into the intricacies of Ollama, its methodologies, its potential impact on AI applications, and what this could mean for the future of human-machine interaction.\n",
      "Table of Content\n",
      "Understanding Ollama\n",
      "Ollama stands for (Omni-Layer Learning Language Acquisition Model), a novel approach to machine learning that promises to redefine how we perceive language acquisition and natural language processing.\n",
      "At its core, Ollama is a groundbreaking platform that democratizes access to large language models (LLMs) by enabling users to run them locally on their machines. Developed with a vision to empower individuals and organizations, Ollama provides a user-friendly interface and seamless integration capabilities, making it easier than ever to leverage the power of LLMs for various applications and use cases.\n",
      "The Genesis of Ollama:\n",
      "Traditional machine learning models have been successful in various linguistic tasks but often require extensive data labelling and preprocessing to function effectively. Ollama emerges as a paradigm shift, utilizing unsupervised learning techniques combined with deep neural networks that enable it to learn language structures without explicit grammatical rules or annotations.\n",
      "Understanding the Ollama Framework:\n",
      "OLLAMA’s architecture comprises multiple layers where each successive layer learns different linguistic patterns and abstract representations of speech. This multi-layered approach allows OLLAMA to progress from understanding basic sounds to grasping complex sentence structures, all without direct human intervention for labelling or structuring the input data.\n",
      "Key Features of Ollama\n",
      "Stepwise Guide to start Ollama\n",
      "Prerequisites:\n",
      "Step 1: Download Ollama\n",
      "Step 2: Install Ollama\n",
      "Step 3: Pull Your First Model (Optional)\n",
      "Replace ‘gemma’ with the specific model name if desired\n",
      "The Ollama library curates a diverse collection of LLMs, each with unique strengths and sizes. Some example are as follows:\n",
      "Step 4: Run and Use the Model\n",
      "Output for command “ollama run phi3”:\n",
      "ollama run phi3\n",
      "Managing Your LLM Ecosystem with the Ollama CLI\n",
      "The Ollama command-line interface (CLI) provides a range of functionalities to manage your LLM collection:\n",
      "The ollama run command is your gateway to interacting with any model on your machine. Need a quick summary of a text file? Pass it through an LLM and let it do the work. Ollama even supports multimodal models that can analyze images alongside text.\n",
      "We can also use ollama using python code as follows:\n",
      "Output:\n",
      "Applications of Ollama\n",
      "Ethical Considerations and Responsible AI\n",
      "While the potential of Ollama is vast and promising, it’s essential to address ethical considerations and ensure responsible AI practices. From mitigating bias and ensuring fairness to prioritizing privacy, transparency, and human oversight, developers and organizations must navigate these challenges to harness the full potential of Ollama while minimizing risks and promoting societal benefit.\n",
      "Conclusion\n",
      "Ollama’s revolutionary approach to natural language understanding heralds a new era where AI can learn and interpret human language as effortlessly as a child does. As researchers continue to refine this innovative model, we stand on the brink of witnessing an unprecedented leap in machine intelligence that could reshape our digital world.\n",
      "As AI technology continues to evolve, Ollama is poised to play a pivotal role in shaping its future development and deployment. With ongoing advancements in model capabilities, hardware optimization, decentralized model sharing, user experiences, and ethical AI frameworks, Ollama remains at the forefront of AI innovation, driving progress and democratization across all sectors of society.\n",
      "Please Login to comment...\n",
      "Similar Reads\n",
      "What kind of Experience do you want to share?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_choice = json.loads(res[\"message\"][\"content\"])[\"action\"][\"tool\"]\n",
    "args = json.loads(res[\"message\"][\"content\"])[\"action\"][\"args\"]\n",
    "\n",
    "# we use a dictionary to map the tool name to the tool function\n",
    "tool_selector = {x.__name__: x for x in tools}\n",
    "\n",
    "# now we select the tool and call it with the arguments\n",
    "observation = tool_selector[tool_choice](**args)\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Within the ReAct framework we would then pass this information back to our LLM via a new `observation` variable. Let's try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"thought\": {\n",
      "    \"thoughts\": \"I need to find out what Ollama refers to in the context of AI\"\n",
      "  },\n",
      "  \"action\": {\n",
      "    \"tool\": \"search\",\n",
      "    \"args\": {\n",
      "      \"query\": \"Ollama AI\"\n",
      "    }\n",
      "  },\n",
      "  \"observation\": \"Ollama Explained: Transforming AI Accessibility and Language Processing\\nIn the rapidly evolving landscape of artificial intelligence (AI), accessibility and innovation are paramount. Among the myriad platforms and tools emerging in this space, one name stands out: Ollama. But what exactly is Ollama, and why is it garnering attention in the AI community? This article delves into the intricacies of Ollama, its methodologies, its potential impact on AI applications, and what this could mean for the future of human-machine interaction.\\nTable of Content\\nUnderstanding Ollama\\nOllama stands for (Omni-Layer Learning Language Acquisition Model), a novel approach to machine learning that promises to redefine how we perceive language acquisition and natural language processing.\\nAt its core, Ollama is a groundbreaking platform that democratizes access to large language models (LLMs) by enabling users to run them locally on their machines. Developed with a vision to empower individuals and organizations, Ollama provides a user-friendly interface and seamless integration capabilities, making it easier than ever to leverage the power of LLMs for various applications and use cases.\\nThe Genesis of Ollama:\\nTraditional machine learning models have been successful in various linguistic tasks but often require extensive data labelling and preprocessing to function effectively. Ollama emerges as a paradigm shift, utilizing unsupervised learning techniques combined with deep neural networks that enable it to learn language structures without explicit grammatical rules or annotations.\\nUnderstanding the Ollama Framework:\\nOLLAMA\\u2019s architecture comprises multiple layers where each successive layer learns different linguistic patterns and abstract representations of speech. This multi-layered approach allows OLLAMA to progress from understanding basic sounds to grasping complex sentence structures, all without direct human intervention for labelling or structuring the input data.\\nKey Features of Ollama\\nStepwise Guide to start Ollama\\nPrerequisites:\\nStep 1: Download Ollama\\nStep 2: Install Ollama\\nStep 3: Pull Your First Model (Optional)\\nReplace \\u2018gemma\\u2019 with the specific model name if desired\\nThe Ollama library curates a diverse collection of LLMs, each with unique strengths and sizes. Some example are as follows:\\nStep 4: Run and Use the Model\\nOutput for command \\u201collama run phi3\\u201d:\\nollama run phi3\\nManaging Your LLM Ecosystem with the Ollama CLI\\nThe Ollama command-line interface (CLI) provides a range of functionalities to manage your LLM collection:\\nThe ollama run command is your gateway to interacting with any model on your machine. Need a quick summary of a text file? Pass it through an LLM and let it do the work. Ollama even supports multimodal models that can analyze images alongside text.\\nWe can also use ollama using python code as follows:\\nOutput:\\nApplications of Ollama\\nEthical Considerations and Responsible AI\\nWhile the potential of Ollama is vast and promising, it\\u2019s essential to address ethical considerations and ensure responsible AI practices. From mitigating bias and ensuring fairness to prioritizing privacy, transparency, and human oversight, developers and organizations must navigate these challenges to harness the full potential of Ollama while minimizing risks and promoting societal benefit.\\nConclusion\\nOllama\\u2019s revolutionary approach to natural language understanding heralds a new era where AI can learn and interpret human language as effortlessly as a child does. As researchers continue to refine this innovative model, we stand on the brink of witnessing an unprecedented leap in machine intelligence that could reshape our digital world.\\nAs AI technology continues to evolve, Ollama is poised to play a pivotal role in shaping its future development and deployment. With ongoing advancements in model capabilities, hardware optimization, decentralized model sharing, user experiences, and ethical AI frameworks, Ollama remains at the forefront of AI innovation, driving progress and democratization across all sectors of society.\\nPlease Login to comment...\\nSimilar Reads\\nWhat kind of Experience do you want to share?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "iteration = json.loads(step)\n",
    "iteration[\"observation\"] = observation\n",
    "iteration_str = json.dumps(iteration, indent=2)\n",
    "print(iteration_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we feed this back into our chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"action\": { \"tool\": \"answer\", \"args\": {\"text\": \"Ollama is a novel approach to machine learning that promises to redefine how we perceive language acquisition and natural language processing.\"}} }\n"
     ]
    }
   ],
   "source": [
    "res = ollama.chat(\n",
    "    model=\"llama3.2:3b-instruct-fp16\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"{system_prompt}\\n\\n{tool_instructions}\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"What is Ollama in the context of AI?\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Step 1:\\n{iteration_str}\\n\\nWhat do I do next to answer the user's question...\"},\n",
    "    ],\n",
    "    format=\"json\",\n",
    "    options={\n",
    "        \"temperature\": 0.0\n",
    "    }\n",
    ")\n",
    "\n",
    "step2 = res[\"message\"][\"content\"]\n",
    "print(step2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! Our final answer from the LLM is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is a novel approach to machine learning that promises to redefine how we perceive language acquisition and natural language processing.\n"
     ]
    }
   ],
   "source": [
    "step2_json = json.loads(step2)\n",
    "print(step2_json[\"action\"][\"args\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now let's take everything we've done so far and use it to construct our ReAct agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "class ReActAgent:\n",
    "    def __init__(self, tools: list[Callable]):\n",
    "        self.messages = []\n",
    "        self.tools = {x.__name__: x for x in tools}\n",
    "        tool_descriptions = [\n",
    "            {\n",
    "                \"name\": tool.__name__,\n",
    "                \"description\": str(inspect.getdoc(tool)),\n",
    "                \"args\": {\n",
    "                    k: str(v).split(\": \")[1] for k, v in inspect.signature(tool).parameters.items()\n",
    "                }\n",
    "            }\n",
    "            for tool in tools\n",
    "        ]\n",
    "        tool_instructions = (\n",
    "            \"You have access to the following tools ONLY, no other tools exist:\\n\\n\"\n",
    "            + \"\\n\".join([str(x) for x in tool_descriptions])\n",
    "        )\n",
    "        self.system_prompt = f\"{system_prompt}\\n\\n{tool_instructions}\"\n",
    "\n",
    "    def __call__(self, prompt: str, max_steps: int = 10):\n",
    "        step_count = 1\n",
    "        while step_count < max_steps:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "\n",
    "        if step_count == max_steps:\n",
    "            # force final answer\n",
    "\n",
    "\n",
    "    def _call_llm(self, messages: list[dict]):\n",
    "        res = ollama.chat(\n",
    "            model=\"llama3.2:3b-instruct-fp16\",\n",
    "            messages=self.messages,\n",
    "            format=\"json\",\n",
    "        )\n",
    "        return res[\"message\"][\"content\"]\n",
    "\n",
    "    def _parse_step(self, step: str):\n",
    "        step_dict = json.loads(step)\n",
    "        tool_choice = step_dict[\"action\"][\"tool\"]\n",
    "        args = step_dict[\"action\"][\"args\"]\n",
    "        tool_selector = {x.__name__: x for x in self.tools}\n",
    "        observation = tool_selector[tool_choice](**args)\n",
    "        return observation\n",
    "\n",
    "    def run_step(self, step_number: int, scratchpad: str):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
